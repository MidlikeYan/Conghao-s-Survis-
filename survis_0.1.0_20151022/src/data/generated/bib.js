define({ entries : {
    "Paper1, Pu_2023_CVPR": {
        "author": "Pu, Nan and Zhong, Zhun and Sebe, Nicu",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "keywords": "type:Generalized Category Discovery",
        "month": "June",
        "pages": "7579-7588",
        "title": "Dynamic Conceptional Contrastive Learning for Generalized Category Discovery",
        "type": "InProceedings",
        "year": "2023"
    },
    "Paper2, Vaze_2022_CVPR": {
        "author": "Vaze, Sagar and Han, Kai and Vedaldi, Andrea and Zisserman, Andrew",
        "booktitle": "Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)",
        "keywords": "type:Generalized Category Discovery",
        "month": "June",
        "pages": "7492-7501",
        "title": "Generalized Category Discovery",
        "type": "InProceedings",
        "year": "2022"
    },
    "Paper3, Wen_2023_ICCV": {
        "author": "Wen, Xin and Zhao, Bingchen and Qi, Xiaojuan",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)",
        "keywords": "type:Generalized Category Discovery",
        "month": "October",
        "pages": "16590-16600",
        "title": "Parametric Classification for Generalized Category Discovery: A Baseline Study",
        "type": "InProceedings",
        "year": "2023"
    },
    "Paper4, wang2024sptnet": {
        "archiveprefix": "arXiv",
        "author": "Hongjun Wang and Sagar Vaze and Kai Han",
        "eprint": "2403.13684",
        "keywords": "type:Generalized Category Discovery",
        "primaryclass": "cs.CV",
        "title": "SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning",
        "type": "misc",
        "year": "2024"
    },
    "Paper5, choi2024contrastive": {
        "archiveprefix": "arXiv",
        "author": "Sua Choi and Dahyun Kang and Minsu Cho",
        "eprint": "2404.09451",
        "keywords": "type:Generalized Category Discovery",
        "primaryclass": "cs.CV",
        "title": "Contrastive Mean-Shift Learning for Generalized Category Discovery",
        "type": "misc",
        "year": "2024"
    },
    "Paper6, NEURIPS2019_1cd138d0": {
        "author": "Berthelot, David and Carlini, Nicholas and Goodfellow, Ian and Papernot, Nicolas and Oliver, Avital and Raffel, Colin A",
        "booktitle": "Advances in Neural Information Processing Systems",
        "editor": "H. Wallach and H. Larochelle and A. Beygelzimer and F. d\\textquotesingle Alch\\'{e}-Buc and E. Fox and R. Garnett",
        "keywords": "type:Semi-supervised Learning",
        "pages": "",
        "publisher": "Curran Associates, Inc.",
        "title": "MixMatch: A Holistic Approach to Semi-Supervised Learning",
        "type": "inproceedings",
        "url": "https://proceedings.neurips.cc/paper_files/paper/2019/file/1cd138d0499a68f4bb72bee04bbec2d7-Paper.pdf",
        "volume": "32",
        "year": "2019"
    },
    "Paper7, pmlr-v119-chen20j": {
        "abstract": "This paper presents SimCLR: a simple framework for contrastive learning of visual representations. We simplify recently proposed contrastive self-supervised learning algorithms without requiring specialized architectures or a memory bank. In order to understand what enables the contrastive prediction tasks to learn useful representations, we systematically study the major components of our framework. We show that (1) composition of data augmentations plays a critical role in defining effective predictive tasks, (2) introducing a learnable nonlinear transformation between the representation and the contrastive loss substantially improves the quality of the learned representations, and (3) contrastive learning benefits from larger batch sizes and more training steps compared to supervised learning. By combining these findings, we are able to considerably outperform previous methods for self-supervised and semi-supervised learning on ImageNet. A linear classifier trained on self-supervised representations learned by SimCLR achieves 76.5% top-1 accuracy, which is a 7% relative improvement over previous state-of-the-art, matching the performance of a supervised ResNet-50. When fine-tuned on only 1% of the labels, we achieve 85.8% top-5 accuracy, outperforming AlexNet with 100X fewer labels.",
        "author": "Chen, Ting and Kornblith, Simon and Norouzi, Mohammad and Hinton, Geoffrey",
        "booktitle": "Proceedings of the 37th International Conference on Machine Learning",
        "editor": "III, Hal Daum\u00e9 and Singh, Aarti",
        "keywords": "type:Contrastive Learning",
        "month": "13--18 Jul",
        "pages": "1597--1607",
        "pdf": "http://proceedings.mlr.press/v119/chen20j/chen20j.pdf",
        "publisher": "PMLR",
        "series": "Proceedings of Machine Learning Research",
        "title": "A Simple Framework for Contrastive Learning of Visual Representations",
        "type": "InProceedings",
        "url": "https://proceedings.mlr.press/v119/chen20j.html",
        "volume": "119",
        "year": "2020"
    },
    "Paper8, 9464163": {
        "author": "Han, Kai and Rebuffi, Sylvestre-Alvise and Ehrhardt, S\u00e9bastien and Vedaldi, Andrea and Zisserman, Andrew",
        "doi": "10.1109/TPAMI.2021.3091944",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "type:Novel Categoriy Discovery",
        "number": "10",
        "pages": "6767-6781",
        "title": "AutoNovel: Automatically Discovering and Learning Novel Visual Categories",
        "type": "ARTICLE",
        "volume": "44",
        "year": "2022"
    },
    "Paper9, Fini_2021_ICCV": {
        "author": "Fini, Enrico and Sangineto, Enver and Lathuili\\`ere, St\\'ephane and Zhong, Zhun and Nabi, Moin and Ricci, Elisa",
        "booktitle": "Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)",
        "keywords": "type:Novel Categoriy Discovery",
        "month": "October",
        "pages": "9284-9292",
        "title": "A Unified Objective for Novel Class Discovery",
        "type": "InProceedings",
        "year": "2021"
    },
    "sPaper10, https://doi.org/10.1002/wics.1270": {
        "abstract": "Cluster analysis methods seek to partition a data set into homogeneous subgroups. It is useful in a wide variety of applications, including document processing and modern genetics. Conventional clustering methods are unsupervised, meaning that there is no outcome variable nor is anything known about the relationship between the observations in the data set. In many situations, however, information about the clusters is available in addition to the values of the features. For example, the cluster labels of some observations may be known, or certain observations may be known to belong to the same cluster. In other cases, one may wish to identify clusters that are associated with a particular outcome variable. This review describes several clustering algorithms (known as \u2018semi-supervised clustering\u2019 methods) that can be applied in these situations. The majority of these methods are modifications of the popular k-means clustering method, and several of them will be described in detail. A brief description of some other semi-supervised clustering algorithms is also provided. This article is categorized under: Statistical Learning and Exploratory Methods of the Data Sciences > Clustering and Classification",
        "author": "Bair, Eric",
        "doi": "https://doi.org/10.1002/wics.1270",
        "eprint": "https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wics.1270",
        "journal": "WIREs Computational Statistics",
        "keywords": "type:Semi-supervised Learning",
        "number": "5",
        "pages": "349-361",
        "title": "Semi-supervised clustering methods",
        "type": "article",
        "url": "https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.1270",
        "volume": "5",
        "year": "2013"
    }
}});